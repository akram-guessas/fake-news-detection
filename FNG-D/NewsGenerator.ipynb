{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48828051-b625-4dce-a4ad-b82e5bafae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 34.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.7.0 tokenizers-0.12.1 transformers-4.19.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be3800d-4520-4994-9710-74b46d65390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gpt2-model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad0a1c6-b044-44f6-94ad-5157f846e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PATH_model = '../Model/output/GPT-2 Model/gpt2-large-model.pth'\n",
    "PATH_tok = \"../Model/output/GPT-2 Model/gpt2-large-tokenizer.pth\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(PATH_model).to(device)\n",
    "tokenizer= torch.load(PATH_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273b092c-2eae-4ac0-867b-aaff520d7ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \\nmodel = GPT2LMHeadModel.from_pretrained('gpt2-large' , pad_token_id = tokenizer.eos_token_id)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large' , pad_token_id = tokenizer.eos_token_id)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ce3922-830e-4b2b-91a1-60a951bed5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\n\\nmodel_PATH = \\'../Model/output/GPT-2 Model/gpt2-xl-model.pth\\'\\ntoc_PATH = \\'../Model/output/GPT-2 Model/gpt2-xl-tokenizer.pth\\'\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nmodel = torch.load(model_PATH).to(device)\\ntokenizer = torch.load(toc_PATH)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "\n",
    "model_PATH = '../Model/output/GPT-2 Model/gpt2-xl-model.pth'\n",
    "toc_PATH = '../Model/output/GPT-2 Model/gpt2-xl-tokenizer.pth'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(model_PATH).to(device)\n",
    "tokenizer = torch.load(toc_PATH)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c164fb6-a754-41de-b6a7-e673cac82f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame From csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0fadb0c-33a2-4749-94d4-104009fabbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('news_for_generation.csv')\n",
    "df = df.iloc[8500:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "090fd078-36ab-4c95-a114-a22b3b052e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2135ef6e-c9a6-4927-96b4-8a1244331668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a635d846-12f2-47f0-963f-c2ab3cf854e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fakenews_generator(df, tokenizer, model, file_name, list):\n",
    "    from datetime import datetime\n",
    "    START = datetime.now()\n",
    "    print(len(df))\n",
    "    i = 1\n",
    "    c = 0\n",
    "    for index, row in df.iterrows():\n",
    "        d={}\n",
    "        sentence = row['title']\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
    "        output = model.generate(input_ids, max_length=1000, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "        fake_news = tokenizer.decode(output[0], skip_special_tokens=True).replace(sentence, '')\n",
    "        c += 1\n",
    "        if i%100 == 0:\n",
    "            print(str(i)+'/'+str(len(df)),' || Time: ' + str(datetime.now() - START), 'Total steps: ' + str(c))\n",
    "        if len(str(fake_news.split())) >= 128:\n",
    "            try:\n",
    "                d['Real title'] = row['title']\n",
    "                d['Generated text'] = fake_news.replace('\\n\\n', '')\n",
    "                d['label'] = 2\n",
    "                list.append(d)\n",
    "            except:\n",
    "                d['Real title'] = row['title']\n",
    "                d['Generated text'] = fake_news\n",
    "                d['label'] = 2\n",
    "                list = list.append(d)\n",
    "            i += 1\n",
    "        else:\n",
    "            pass\n",
    "    pd.DataFrame(list).to_csv('Dataset/generated_article' + str(file_name) +'.csv', index=False)\n",
    "    print(datetime.now() - START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15c1d61d-bdb0-4e40-806e-b1c9aad5b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "100/500  || Time: 0:22:26.118572 Total steps: 111\n",
      "200/500  || Time: 0:51:20.714220 Total steps: 217\n",
      "300/500  || Time: 1:16:46.485315 Total steps: 329\n",
      "400/500  || Time: 1:40:08.130879 Total steps: 438\n",
      "1:53:44.311804\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    file_name = 11\n",
    "    list = []\n",
    "    fakenews_generator(df, tokenizer, model, file_name, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10dbf0ea-497b-4f9d-bbce-a22dc46fb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('Dataset/generated_article9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ab26f3-d1aa-43fc-80f4-8bb1522bd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 462 entries, 0 to 461\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Real title      462 non-null    object\n",
      " 1   Generated text  462 non-null    object\n",
      " 2   label           462 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 11.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4885efa-c658-4227-a9b2-bd4fed2d0982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for index, text in df_test.iterrows():\n",
    "    if len(str(text['Generated text']).split())< 50:\n",
    "        c += 1\n",
    "        \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3eff1d0-db44-4246-a862-51cc76fae31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nc = 0\\nlist_test = []\\nfor index, row in df_test.iterrows():\\n    d = {}\\n    if len(str(row['Generated text'])) >= 128:\\n        c += 1\\n        print(row['Generated text'])\\n        print('##################')\\n        break\\n    else:\\n        pass\\n    \\nprint(c)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "c = 0\n",
    "list_test = []\n",
    "for index, row in df_test.iterrows():\n",
    "    d = {}\n",
    "    if len(str(row['Generated text'])) >= 128:\n",
    "        c += 1\n",
    "        print(row['Generated text'])\n",
    "        print('##################')\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40aa4a62-dfa8-4b15-9b14-36426df1aece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30292af13954142a5a387cf6aaac21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84afde547b447b1988d904e3dec718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee5c7badc6e4821997749e000374a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40b15a066ae4242ba8fc79e82cdb80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "992c6c61-db9d-4ee3-a874-e16f7a2e354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(list_test).to_csv(\"Dataset/generated_article.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f1518-de41-4804-afb5-36c85a03afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['Generated text'].iloc[25].replace('\\n\\n', '').isnull()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

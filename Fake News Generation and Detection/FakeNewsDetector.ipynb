{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Asm45_mIzgbO"
   },
   "source": [
    "# **Install Transformers Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2hjXehEP0s6",
    "outputId": "d8ff77b3-7c7f-46c5-c22c-a2835c98c736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Zel3ZgN0jvQ",
    "tags": []
   },
   "source": [
    "# Importing the libraries needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f-wsjMT9zrul"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    BertForSequenceClassification, \n",
    "    AlbertForSequenceClassification, \n",
    "    XLNetForSequenceClassification, \n",
    "    RobertaForSequenceClassification, \n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from transformers import RobertaModel, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")  \n",
    "from sys import platform\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = 512\n",
    "# lr=1.25e-6\n",
    "# Batch size\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "EVAL_BATCH_SIZE = 16\n",
    "PREDICT_BATCH_SIZE = 16\n",
    "# Learning Rate\n",
    "LEARNING_RATE = 1.25e-6 # 1e-6, 2e-5, 1e-4, 1e-3\n",
    "# Epochs\n",
    "NUM_TRAIN_EPOCHS = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding sentences **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lmeq3SLCVd_A"
   },
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Encoding sentences\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_tokenizer, df, max_seq_len = MAX_SEQ_LENGTH):\n",
    "        super(NewsDataset, self).__init__()\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.input_ids, self.attention_mask, self.token_type_ids, self.labels = self.get_input(df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.token_type_ids[idx], self.labels[idx]\n",
    "        \n",
    "    # Convert dataframe to tensor\n",
    "    def get_input(self, df):\n",
    "        text = df['text'].values\n",
    "        labels = df['label'].values\n",
    "        \n",
    "        # tokenizer\n",
    "        tokens_seq = list(map(self.bert_tokenizer.tokenize, text)) # list of shape [sentence_len, token_len]\n",
    "        \n",
    "        # Get fixed-length sequence and its mask\n",
    "        result = list(map(self.trunate_and_pad, tokens_seq))\n",
    "        \n",
    "        input_ids = [i[0] for i in result]\n",
    "        attention_mask = [i[1] for i in result]\n",
    "        token_type_ids = [i[2] for i in result]\n",
    "        \n",
    "        return (\n",
    "               torch.Tensor(input_ids).type(torch.long), \n",
    "               torch.Tensor(attention_mask).type(torch.long),\n",
    "               torch.Tensor(token_type_ids).type(torch.long), \n",
    "               torch.Tensor(labels).type(torch.long)\n",
    "               )\n",
    "    \n",
    "    def trunate_and_pad(self, tokens_seq):\n",
    "        # Concat '[CLS]' at the beginning\n",
    "        tokens_seq = ['[CLS]'] + tokens_seq     \n",
    "        # Truncate sequences of which the lengths exceed the max_seq_len\n",
    "        if len(tokens_seq) > self.max_seq_len:\n",
    "            tokens_seq = tokens_seq[0 : self.max_seq_len]           \n",
    "        # Generate padding\n",
    "        padding = [0] * (self.max_seq_len - len(tokens_seq))       \n",
    "        # Convert tokens_seq to token_ids\n",
    "        input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens_seq)\n",
    "        input_ids += padding   \n",
    "        # Create attention_mask\n",
    "        attention_mask = [1] * len(tokens_seq) + padding     \n",
    "        # Create token_type_ids\n",
    "        token_type_ids = [0] * (self.max_seq_len)\n",
    "        \n",
    "        assert len(input_ids) == self.max_seq_len\n",
    "        assert len(attention_mask) == self.max_seq_len\n",
    "        assert len(token_type_ids) == self.max_seq_len\n",
    "        \n",
    "        return input_ids, attention_mask, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = 'roberta-base'\n",
    "bert_model = 'roberta-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and save modle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased', num_labels = 2)\\ntokenizer = AutoTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)\\ntorch.save(model, 'Model/output/Xlnet/Xlnet_base/model-xlnet-large-cased.pth.tar')\\ntorch.save(tokenizer, 'Model/output/Xlnet/Xlnet_base/tokenizer-xlnet-large-cased.pth.tar')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased', num_labels = 2)\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)\n",
    "torch.save(model, 'Model/output/Xlnet/Xlnet_base/model-xlnet-large-cased.pth.tar')\n",
    "torch.save(tokenizer, 'Model/output/Xlnet/Xlnet_base/tokenizer-xlnet-large-cased.pth.tar')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, requires_grad = True):\n",
    "        super(BertModel, self).__init__()\n",
    "        # self.bert = BertForSequenceClassification.from_pretrained('textattack/bert-base-uncased-SST-2',num_labels = 2)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-SST-2', do_lower_case=True)\n",
    "        self.bert = torch.load('Model/output/BERT/BERT_base/model-berta-base.pth.tar')\n",
    "        self.tokenizer = torch.load('Model/output/BERT/BERT_base/tokenizer-berta-base.pth.tar')\n",
    "        self.requires_grad = requires_grad\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = requires_grad  # Each parameter requires gradient\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
    "        loss, logits = self.bert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
    "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        return loss, logits, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albert Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbertModel(nn.Module):\n",
    "    def __init__(self, requires_grad = True):\n",
    "        super(AlbertModel, self).__init__()\n",
    "        # self.albert = AlbertForSequenceClassification.from_pretrained('albert-xxlarge-v2', num_labels = 2)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained('albert-xxlarge-v2', do_lower_case=True)\n",
    "        self.albert = torch.load('Model/output/Albert/Albert_base/model-albert-xxlarge-v2.pth.tar')\n",
    "        self.tokenizer = torch.load('Model/output/Albert/Albert_base/tokenizer-albert-xxlarge-v2.pth.tar')\n",
    "        self.requires_grad = requires_grad\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        for param in self.albert.parameters():\n",
    "            param.requires_grad = True  # Each parameter requires gradient\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
    "        loss, logits = self.albert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
    "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        return loss, logits, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "peu-R7XcKjME"
   },
   "outputs": [],
   "source": [
    "class RobertModel(nn.Module):\n",
    "    def __init__(self, requires_grad = True):\n",
    "        super(RobertModel, self).__init__()\n",
    "        # config = RobertaForSequenceClassification.from_pretrained( 'roberta-base', output_hidden_states=True, num_labels = 2)    \n",
    "        # self.bert = RobertaForSequenceClassification.from_pretrained(bert_model, output_hidden_states=True, num_labels = 2)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "        self.bert = torch.load('Model/output/Roberta/Roberta-base/model-roberta-base.pth')\n",
    "        self.tokenizer = torch.load('Model/output/Roberta/Roberta-base/tokenizer-roberta-base.pth')\n",
    "        self.requires_grad = requires_grad\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = requires_grad  # Each parameter requires gradient\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels = None):\n",
    "\n",
    "        loss, logits = self.bert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
    "                                  token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
    "        # print(logits)\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        # print(probabilities)\n",
    "        return loss, logits, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xlnet Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlnetModel(nn.Module):\n",
    "    def __init__(self, requires_grad = True):\n",
    "        super(XlnetModel, self).__init__()\n",
    "        # self.xlnet = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased', num_labels = 2)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)\n",
    "        self.xlnet = torch.load('Model/output/Xlnet/Xlnet_base/model-xlnet-large-cased.pth.tar')\n",
    "        self.tokenizer = torch.load('Model/output/Xlnet/Xlnet_base/tokenizer-xlnet-large-cased.pth.tar')\n",
    "        self.requires_grad = requires_grad\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = requires_grad  # Each parameter requires gradient\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
    "        loss, logits = self.xlnet(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
    "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        return loss, logits, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = BertModel(requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = AlbertModel(requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = RobertModel(requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = XlnetModel(requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Predictions Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tnl2PiJzR7Dn"
   },
   "outputs": [],
   "source": [
    "def correct_predictions(output_probabilities, targets):\n",
    "    _, out_classes = output_probabilities.max(dim=1)\n",
    "    correct = (out_classes == targets).sum()\n",
    "    return correct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NPVQZMFSSDmY"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, epoch_number, max_gradient_norm, scheduler):\n",
    "    # Switch the model to train mode.\n",
    "    model.train()\n",
    "    device = model.device\n",
    "    epoch_start = time.time()\n",
    "    batch_time_avg = 0.0\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    accuracy = 0.0\n",
    "    loss_app = 0.0\n",
    "    tqdm_batch_iterator = tqdm(dataloader)\n",
    "    for batch_index, (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in enumerate(tqdm_batch_iterator):\n",
    "        batch_start = time.time()\n",
    "        # Move input and output data to the GPU if it is used.\n",
    "        seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        batch_time_avg += time.time() - batch_start\n",
    "        running_loss += loss.item()\n",
    "        correct_preds += correct_predictions(probabilities, labels)\n",
    "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
    "                      .format(batch_time_avg/(batch_index+1), running_loss/(batch_index+1))\n",
    "        tqdm_batch_iterator.set_description(description)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
    "    return epoch_time, epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    # Switch to evaluate mode.\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    all_prob = []\n",
    "    all_labels = []\n",
    "    # Deactivate autograd for evaluation.\n",
    "    with torch.no_grad():\n",
    "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
    "            # Move input and output data to the GPU if one is used.\n",
    "            seqs = batch_seqs.to(device)\n",
    "            masks = batch_seq_masks.to(device)\n",
    "            segments = batch_seq_segments.to(device)\n",
    "            labels = batch_labels.to(device)\n",
    "            loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += correct_predictions(probabilities, labels)\n",
    "            all_prob.extend(probabilities[:,1].cpu().numpy())\n",
    "            all_labels.extend(batch_labels)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
    "    return epoch_time, epoch_loss, epoch_accuracy, roc_auc_score(all_labels, all_prob), all_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "feCPvyQ-RoSl"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    # Switch the model to eval mode.\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    time_start = time.time()\n",
    "    batch_time = 0.0\n",
    "    accuracy = 0.0\n",
    "    all_prob = []\n",
    "    all_labels = []\n",
    "    # Deactivate autograd for evaluation.\n",
    "    with torch.no_grad():\n",
    "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
    "            batch_start = time.time()\n",
    "            # Move input and output data to the GPU if one is used.\n",
    "            seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
    "            _, _, probabilities = model(seqs, masks, segments, labels)\n",
    "            accuracy += correct_predictions(probabilities, labels)\n",
    "            batch_time += time.time() - batch_start\n",
    "            all_prob.extend(probabilities[:,1].cpu().numpy())\n",
    "            all_labels.extend(batch_labels)\n",
    "    batch_time /= len(dataloader)\n",
    "    total_time = time.time() - time_start\n",
    "    accuracy /= (len(dataloader.dataset))\n",
    "\n",
    "    return batch_time, total_time, accuracy, all_prob, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ,Validation and testing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_validate_test(train_df, dev_df, test_df, target_dir, \n",
    "         max_seq_len=MAX_SEQ_LENGTH,\n",
    "         epochs=NUM_TRAIN_EPOCHS,\n",
    "         batch_size=TRAIN_BATCH_SIZE,\n",
    "         lr=LEARNING_RATE,\n",
    "         patience=1,\n",
    "         max_grad_norm=10.0,\n",
    "         if_save_model=True,\n",
    "         checkpoint=None):\n",
    "\n",
    "    tokenizer = bertmodel.tokenizer\n",
    "    \n",
    "    print(20 * \"=\", \" Preparing for training \", 20 * \"=\")\n",
    "    # Path to save the model, create a folder if not exist.\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "        \n",
    "    # -------------------- Data loading --------------------------------------#\n",
    "    print(\"\\t* Loading training data...\")\n",
    "    train_data = NewsDataset(tokenizer,train_df, max_seq_len=max_seq_len)\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\t* Loading validation data...\")\n",
    "    dev_data = NewsDataset(tokenizer, dev_df, max_seq_len=max_seq_len)\n",
    "    dev_loader = DataLoader(dev_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    print(\"\\t* Loading test data...\")\n",
    "    test_data = NewsDataset(tokenizer, test_df, max_seq_len=max_seq_len) \n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    # -------------------- Model definition ------------------- --------------#\n",
    "    \n",
    "    print(\"\\t* Building model...\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = bertmodel.to(device)\n",
    "    \n",
    "    # -------------------- Preparation for training  -------------------------#\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "            {\n",
    "                    'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                    'weight_decay':0.01\n",
    "            },\n",
    "            {\n",
    "                    'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                    'weight_decay':0.0\n",
    "            }\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    total_steps = len(train_data) * epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                num_training_steps = total_steps)\n",
    "    \n",
    "    best_score = 0.0\n",
    "    start_epoch = 1\n",
    "    # Data for loss curves plot\n",
    "    epochs_count = []\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "    valid_aucs = []\n",
    "    epoch_times = []\n",
    "    # Continuing training from a checkpoint if one was given as argument\n",
    "    if checkpoint:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_score = checkpoint[\"best_score\"]\n",
    "        print(\"\\t* Training will continue on existing model from epoch {}...\".format(start_epoch))\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        epochs_count = checkpoint[\"epochs_count\"]\n",
    "        train_losses = checkpoint[\"train_losses\"]\n",
    "        train_accuracy = checkpoint[\"train_accuracy\"]\n",
    "        valid_losses = checkpoint[\"valid_losses\"]\n",
    "        valid_accuracy = checkpoint[\"valid_accuracy\"]\n",
    "        valid_auc = checkpoint[\"valid_auc\"]\n",
    "        epoch_times = checkpoint[\"epoch_times\"]\n",
    "     # Compute loss and accuracy before starting (or resuming) training.\n",
    "    _, valid_loss, valid_accuracy, auc, _ = validate(model, dev_loader)\n",
    "    train_losses.append(valid_loss)\n",
    "    train_accuracies.append(valid_accuracy) \n",
    "    #######################################\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "    valid_aucs.append(auc)\n",
    "    print(\"\\n* Validation loss before training: {:.4f}, accuracy: {:.4f}%, auc: {:.4f}\".format(valid_loss, (valid_accuracy*100), auc))\n",
    "    \n",
    "    # -------------------- Training epochs -----------------------------------#\n",
    "    \n",
    "    print(\"\\n\", 20 * \"=\", \"Training bert model on device: {}\".format(device), 20 * \"=\")\n",
    "    patience_counter = 0\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "        epochs_count.append(epoch)\n",
    "\n",
    "        print(\"* Training epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy = train(model, train_loader, optimizer, epoch, max_grad_norm, scheduler)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)  \n",
    "        epoch_times.append(epoch_time)\n",
    "        print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\".format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "        \n",
    "        print(\"* Validation for epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy , epoch_auc, _ = validate(model, dev_loader)\n",
    "        valid_losses.append(epoch_loss)\n",
    "        valid_accuracies.append(epoch_accuracy)\n",
    "        valid_aucs.append(epoch_auc)\n",
    "        print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, auc: {:.4f}\\n\"\n",
    "              .format(epoch_time, epoch_loss, (epoch_accuracy*100), epoch_auc))\n",
    "    \n",
    "        # Early stopping on validation accuracy.\n",
    "        if epoch_accuracy < best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = epoch_accuracy\n",
    "            patience_counter = 0\n",
    "            if (if_save_model):\n",
    "                # torch.save(model.state_dict(), os.path.join(target_dir, \"model_none.pth\"))\n",
    "                torch.save({\"epoch\": epoch, \n",
    "                       \"model\": model.state_dict(),\n",
    "                       \"optimizer\": optimizer.state_dict(),\n",
    "                       \"tokenizer\":tokenizer,\n",
    "                       \"best_score\": best_score,\n",
    "                       \"epochs_count\": epochs_count,\n",
    "                       \"train_losses\": train_losses,\n",
    "                       \"train_accuracy\": train_accuracies,\n",
    "                       \"valid_losses\": valid_losses,\n",
    "                       \"valid_accuracy\": valid_accuracies,\n",
    "                       \"valid_auc\": valid_aucs,\n",
    "                       \"epoch_times\": epoch_times,\n",
    "                       },\n",
    "                       os.path.join(target_dir, \"model_albert.pth.tar\"))\n",
    "    \n",
    "                print(\"save model succesfully!\\n\")\n",
    "            \n",
    "            # run model on test set and save the prediction result to csv\n",
    "            print(\"* Test for epoch {}:\".format(epoch))\n",
    "            _, _, test_accuracy, _, all_prob = validate(model, test_loader)\n",
    "            print(\"Test accuracy: {:.4f}%\\n\".format(test_accuracy))\n",
    "            test_prediction = pd.DataFrame({'prob_1':all_prob})\n",
    "            test_prediction['prob_0'] = 1-test_prediction['prob_1']\n",
    "            test_prediction['prediction'] = test_prediction.apply(lambda x: 0 if (x['prob_0'] > x['prob_1']) else 1, axis=1)\n",
    "            test_prediction = test_prediction[['prob_0', 'prob_1', 'prediction']]\n",
    "            test_prediction.to_csv(os.path.join(target_dir,\"test_prediction_model3.csv\"), index=False)\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trining Data info: (24353, 4)\n",
      "Validation Data info: (8117, 4)\n",
      "Testing Data info: (1, 5)\n",
      "====================  Preparing for training  ====================\n",
      "\t* Loading training data...\n",
      "\t* Loading validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Loading test data...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Validation loss before training: 1.2464, accuracy: 45.4232%, auc: 0.5096\n",
      "\n",
      " ==================== Training bert model on device: cuda ====================\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 2.3311s, loss: 0.9491:   2%|‚ñè         | 26/1523 [02:26<2:20:36,  5.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Data info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m target_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel/output/Albert\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_train_validate_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mmodel_train_validate_test\u001b[0;34m(train_df, dev_df, test_df, target_dir, max_seq_len, epochs, batch_size, lr, patience, max_grad_norm, if_save_model, checkpoint)\u001b[0m\n\u001b[1;32m    146\u001b[0m epochs_count\u001b[38;5;241m.\u001b[39mappend(epoch)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m* Training epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m--> 149\u001b[0m epoch_time, epoch_loss, epoch_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m    151\u001b[0m train_accuracies\u001b[38;5;241m.\u001b[39mappend(epoch_accuracy)  \n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, epoch_number, max_gradient_norm, scheduler)\u001b[0m\n\u001b[1;32m     35\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m batch_time_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m batch_start\n\u001b[0;32m---> 37\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m correct_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correct_predictions(probabilities, labels)\n\u001b[1;32m     39\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvg. batch proc. time: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124ms, loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     40\u001b[0m               \u001b[38;5;241m.\u001b[39mformat(batch_time_avg\u001b[38;5;241m/\u001b[39m(batch_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), running_loss\u001b[38;5;241m/\u001b[39m(batch_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_path = \"../Datasets/HuggingFaceDataset/cc_news/\"\n",
    "    train_df = pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "    print(f\"Trining Data info: {train_df.shape}\")\n",
    "    val_df = pd.read_csv(os.path.join(data_path,\"val.csv\"))\n",
    "    print(f\"Validation Data info: {val_df.shape}\")\n",
    "    test_df = pd.read_csv(os.path.join(data_path,\"test.csv\")).head(1)\n",
    "    print(f\"Testing Data info: {test_df.shape}\")\n",
    "    target_dir = \"Model/\"\n",
    "    model_train_validate_test(train_df, val_df, test_df, target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_test(test_df, target_dir,\n",
    "                    test_prediction_dir,\n",
    "                    test_prediction_name,\n",
    "                    max_seq_len=MAX_SEQ_LENGTH, batch_size=PREDICT_BATCH_SIZE):\n",
    "    \n",
    "    bertmodel = RobertModel(requires_grad = True)\n",
    "    tokenizer = bertmodel.tokenizer\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    print(20 * \"=\", \" Preparing for testing \", 20 * \"=\")\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        checkpoint = torch.load(os.path.join(target_dir, \"roberta-model2.pth.tar\"))\n",
    "    else:\n",
    "        checkpoint = torch.load(os.path.join(target_dir, \"roberta-model2.pth.tar\"), map_location=device)\n",
    "        \n",
    "    print(\"\\t* Loading test data...\")    \n",
    "    test_data = NewsDataset(tokenizer,test_df, max_seq_len = max_seq_len) \n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # Retrieving model parameters from checkpoint.\n",
    "    print(\"\\t* Building model...\")\n",
    "    model = bertmodel.to(device)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    print(20 * \"=\", \" Testing BERT model on device: {} \".format(device), 20 * \"=\")\n",
    "    \n",
    "    batch_time, total_time, accuracy, all_prob, all_labels = test(model, test_loader)\n",
    "    print(\"\\n-> Average batch processing time: {:.4f}s, total test time: {:.4f}s, accuracy: {:.4f}%\\n\".format(batch_time, total_time, (accuracy*100)))\n",
    "    \n",
    "    test_prediction = pd.DataFrame({'prob_1':all_prob})\n",
    "    test_prediction['prob_0'] = 1-test_prediction['prob_1']\n",
    "    test_prediction['prediction'] = test_prediction.apply(lambda x: 0 if (x['prob_0'] > x['prob_1']) else 1, axis=1)\n",
    "    test_prediction['label'] = [i.item() for i in all_labels]\n",
    "    test_prediction = test_prediction[['prob_0', 'prob_1', 'prediction','label']]\n",
    "    \n",
    "    if not os.path.exists(test_prediction_dir):\n",
    "        os.makedirs(test_prediction_dir)\n",
    "    test_prediction.to_csv(os.path.join(test_prediction_dir, test_prediction_name), index=False)\n",
    "\n",
    "    y_actu = all_labels\n",
    "    y_pred = test_prediction['prediction'].to_list()\n",
    "    cf_matrix = confusion_matrix(y_actu, y_pred)\n",
    "    class_rep = classification_report(y_actu, y_pred,labels=[0,1],output_dict=True)\n",
    "    return cf_matrix, class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preparing for testing  ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Loading test data...\n",
      "\t* Building model...\n",
      "====================  Testing BERT model on device: cuda  ====================\n",
      "\n",
      "-> Average batch processing time: 0.3947s, total test time: 200.9943s, accuracy: 98.1767%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    test_df = pd.read_csv('../Datasets/HuggingFaceDataset/GonzaloA-fake_news/Dataset(02)/test.csv')\n",
    "    target_dir = 'Model/output/Roberta/'\n",
    "    test_prediction_dir = 'Model/output/Roberta/test_pred'\n",
    "    test_prediction_name = 'test_prediction_model02.csv' \n",
    "    MAX_SEQ_LENGTH = 512\n",
    "    cf_matrix, class_rep = model_load_test(test_df, target_dir,test_prediction_dir,test_prediction_name,max_seq_len=MAX_SEQ_LENGTH, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# .iloc[:-1, :] to exclude support\n",
    "crp_plot = sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :].T, annot=True)\n",
    "crp_plot\n",
    "crp_plot.figure.savefig(\"model1_class_rep.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_plot = sns.heatmap(cf_matrix, annot=True)\n",
    "cfm_plot.figure.savefig(\"model1_cfm.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XLM-Roberta_for_textClasification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
